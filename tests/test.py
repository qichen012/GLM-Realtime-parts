import json
import base64
import websocket
import sounddevice as sd
import numpy as np
import threading
import queue
import time
import jwt, os
import sys

# --- å…¨å±€å˜é‡ ---
API_KEY = os.getenv("ZHIPU_API_KEY")
WS_URL = "wss://open.bigmodel.cn/api/paas/v4/realtime?model=GLM-Realtime"

SAMPLE_RATE = 16000
CHUNK = 1024
CHUNK_DURATION = CHUNK / SAMPLE_RATE  # 0.064 ç§’

audio_queue = queue.Queue()
session_ready = threading.Event()
stop_event = threading.Event()

# çŠ¶æ€è¿½è¸ª
last_audio_time = time.time()
is_speaking = False

# éŸ³é¢‘æ’­æ”¾ç¼“å†²
audio_playback_buffer = []
playback_lock = threading.Lock()

# --- æ ¸å¿ƒå‡½æ•° ---

def generate_jwt_token(api_key: str, exp_seconds: int = 3600) -> str:
    """Generate JWT token for authentication."""
    try:
        api_key_id, api_key_secret = api_key.split('.')
    except ValueError:
        raise ValueError("API Key format is incorrect, should be 'API_KEY_ID.API_KEY_SECRET'")
    current_time = int(time.time())
    payload = {"api_key": api_key_id, "exp": current_time + exp_seconds, "timestamp": current_time}
    encoded_jwt = jwt.encode(payload, api_key_secret, algorithm="HS256",
                             headers={"alg": "HS256", "sign_type": "SIGN"})
    return encoded_jwt

def callback(indata, frames, time_info, status):
    """sounddevice input stream callback function."""
    global last_audio_time, is_speaking
    
    if status:
        print("Microphone Warning:", status, file=sys.stderr)
    
    volume_norm = np.linalg.norm(indata) * 10 
    
    if volume_norm > 0.5:
        print(f"ğŸ”Š Sound Detected (Level: {volume_norm:.1f})", end='\r', file=sys.stdout, flush=True)
        last_audio_time = time.time()
        is_speaking = True

    if not stop_event.is_set():
        audio_queue.put(indata.copy())

def send_audio_loop(ws):
    """
    ä¼˜åŒ–ç‰ˆéŸ³é¢‘å‘é€ï¼š
    1. ä½¿ç”¨é€Ÿç‡é™åˆ¶å™¨ï¼Œç¡®ä¿ä¸è¶…è¿‡ 50 QPS
    2. æ‰¹é‡ç´¯ç§¯éŸ³é¢‘ï¼Œå‡å°‘è¯·æ±‚æ¬¡æ•°
    3. æ™ºèƒ½æ£€æµ‹é™éŸ³å¹¶è§¦å‘å“åº”
    """
    global is_speaking, last_audio_time
    
    session_ready.wait()
    print("ğŸ¤ Session ready, starting to send audio stream")
    
    # é€Ÿç‡é™åˆ¶é…ç½®
    MAX_QPS = 45  # ä¿å®ˆä¸€ç‚¹ï¼Œä½¿ç”¨45è€Œä¸æ˜¯50
    MIN_INTERVAL = 1.0 / MAX_QPS  # æ¯æ¬¡è¯·æ±‚æœ€å°é—´éš” â‰ˆ 0.022ç§’
    
    # æ‰¹é‡å‘é€é…ç½®
    BATCH_SIZE = 8  # æ¯æ¬¡ç´¯ç§¯8ä¸ªchunk (8 * 64ms = 512ms éŸ³é¢‘)
    SILENCE_THRESHOLD = 1.5  # é™éŸ³1.5ç§’è§¦å‘å“åº”
    
    audio_batch = []
    last_send_time = 0
    
    while not stop_event.is_set():
        try:
            chunk = audio_queue.get(timeout=0.05)
            audio_batch.append(chunk)
            
            # å½“ç´¯ç§¯åˆ°è¶³å¤Ÿçš„éŸ³é¢‘ ä¸” æ»¡è¶³é€Ÿç‡é™åˆ¶
            if len(audio_batch) >= BATCH_SIZE:
                # ç¡®ä¿æ»¡è¶³æœ€å°é—´éš”
                time_since_last_send = time.time() - last_send_time
                if time_since_last_send < MIN_INTERVAL:
                    time.sleep(MIN_INTERVAL - time_since_last_send)
                
                # å‘é€æ‰¹é‡éŸ³é¢‘
                combined_audio = np.concatenate(audio_batch)
                audio_base64 = base64.b64encode(combined_audio.tobytes()).decode("utf-8")
                
                ws.send(json.dumps({
                    "type": "input_audio_buffer.append",
                    "audio": audio_base64
                }))
                
                last_send_time = time.time()
                audio_batch.clear()
                
                # æ¸…ç©ºé˜Ÿåˆ—ä¸­çš„å·²å¤„ç†ä»»åŠ¡
                for _ in range(BATCH_SIZE):
                    try:
                        audio_queue.task_done()
                    except:
                        pass

        except queue.Empty:
            # æ£€æµ‹é™éŸ³å¹¶è§¦å‘å“åº”
            if is_speaking and (time.time() - last_audio_time) > SILENCE_THRESHOLD:
                print("\nâ¸ï¸  Detected silence, committing audio and requesting response...")
                
                # å‘é€å‰©ä½™çš„éŸ³é¢‘
                if audio_batch:
                    # æ»¡è¶³é€Ÿç‡é™åˆ¶
                    time_since_last_send = time.time() - last_send_time
                    if time_since_last_send < MIN_INTERVAL:
                        time.sleep(MIN_INTERVAL - time_since_last_send)
                    
                    combined_audio = np.concatenate(audio_batch)
                    audio_base64 = base64.b64encode(combined_audio.tobytes()).decode("utf-8")
                    ws.send(json.dumps({
                        "type": "input_audio_buffer.append",
                        "audio": audio_base64
                    }))
                    audio_batch.clear()
                    last_send_time = time.time()
                
                # çŸ­æš‚ç­‰å¾…ï¼Œç„¶åcommit
                time.sleep(MIN_INTERVAL)
                ws.send(json.dumps({"type": "input_audio_buffer.commit"}))
                
                # å†ç­‰å¾…ä¸€ä¸‹ï¼Œç„¶åè¯·æ±‚å“åº”
                time.sleep(MIN_INTERVAL)
                response_request = {
                    "type": "response.create",
                    "response": {
                        "modalities": ["audio", "text"],
                        "instructions": "è¯·ç”¨è¯­éŸ³å›å¤"
                    }
                }
                print(f"ğŸ“¤ Sending response request: {json.dumps(response_request, ensure_ascii=False)}")
                ws.send(json.dumps(response_request))
                
                is_speaking = False
                last_send_time = time.time()
                print("ğŸ“¤ Response creation requested")
            
            continue
        
        except Exception as e:
            print(f"\nâŒ Send error: {e}")
            break
            
    print("ğŸ¤ Audio sending thread exited.")


def on_message(ws, message):
    """Handles incoming WebSocket messages."""
    data = json.loads(message)
    msg_type = data.get("type")
    
    # åªåœ¨å…³é”®æ¶ˆæ¯æ—¶æ‰“å°è¯¦ç»†ä¿¡æ¯
    if msg_type in ("session.created", "session.updated", "error", "session.error"):
        print(f"\nğŸ“¡ [{msg_type}] {json.dumps(data, ensure_ascii=False, indent=2)}")
    
    if msg_type in ("session.created", "session.updated"):
        print("âœ… Session Info:", data.get("session", {}).get("id"))
        session_ready.set()
        
    elif msg_type == "transcript":
        transcript_text = data.get('text', '')
        if transcript_text:
            print(f"\nğŸ“ Transcription: {transcript_text}")
        
    elif msg_type == "response.text.delta":
        text = data.get("text", "")
        if text:
            sys.stdout.write(text)
            sys.stdout.flush()
        
    elif msg_type == "response.text.done":
        sys.stdout.write("\n")
        sys.stdout.flush()
        
    elif msg_type == "response.audio.delta":
        try:
            audio_base64 = data.get("audio", "")
            if not audio_base64:
                print(f"\nâš ï¸  Received audio.delta with empty audio field!")
                return
                
            audio_bytes = base64.b64decode(audio_base64)
            audio_np = np.frombuffer(audio_bytes, dtype=np.int16)
            
            # è°ƒè¯•ä¿¡æ¯
            print(f"\nğŸ”Š Audio chunk: {len(audio_bytes)} bytes, {len(audio_np)} samples", end="", flush=True)
            
            # ç´¯ç§¯éŸ³é¢‘åˆ°ç¼“å†²åŒº
            with playback_lock:
                audio_playback_buffer.append(audio_np)
            
        except Exception as e:
            print(f"\nâŒ Audio processing error: {e}")
            import traceback
            traceback.print_exc()
            
    elif msg_type == "response.audio.done":
        try:
            print(f"\n\nğŸµ Audio stream complete, preparing playback...")
            
            with playback_lock:
                if audio_playback_buffer:
                    print(f"   Buffered chunks: {len(audio_playback_buffer)}")
                    
                    # åˆå¹¶æ‰€æœ‰éŸ³é¢‘å—
                    full_audio = np.concatenate(audio_playback_buffer)
                    print(f"   Total samples: {len(full_audio)}, duration: {len(full_audio)/SAMPLE_RATE:.2f}s")
                    print(f"   Audio range: [{full_audio.min()}, {full_audio.max()}]")
                    
                    # å¢åŠ éŸ³é‡ï¼ˆå¦‚æœå¤ªå°ï¼‰
                    max_val = np.abs(full_audio).max()
                    if max_val > 0:
                        if max_val < 10000:
                            volume_boost = 10000 / max_val
                            full_audio = (full_audio * volume_boost).astype(np.int16)
                            print(f"   ğŸ”Š Volume boosted by {volume_boost:.2f}x")
                        
                        # æ’­æ”¾éŸ³é¢‘
                        print(f"   â–¶ï¸  Playing audio now...")
                        sd.play(full_audio, samplerate=SAMPLE_RATE, blocking=True)
                        print("   âœ… Playback complete!")
                    else:
                        print("   âš ï¸  Audio data is silent (all zeros)")
                    
                    audio_playback_buffer.clear()
                else:
                    print("   âš ï¸  No audio chunks were buffered!")
                    
        except Exception as e:
            print(f"\nâŒ Error during playback: {e}")
            import traceback
            traceback.print_exc()
            
    elif msg_type == "response.output_item.done":
        # â­ å…³é”®å‘ç°ï¼šæ™ºè°± API æŠŠéŸ³é¢‘æ”¾åœ¨è¿™é‡Œï¼
        try:
            item = data.get("item", {})
            content_list = item.get("content", [])
            
            for content in content_list:
                if content.get("type") == "audio":
                    audio_base64 = content.get("audio", "")
                    
                    if audio_base64:
                        print(f"\nğŸµ Found audio in output_item.done!")
                        
                        # è§£ç éŸ³é¢‘
                        audio_bytes = base64.b64decode(audio_base64)
                        full_audio = np.frombuffer(audio_bytes, dtype=np.int16)
                        
                        print(f"   Total samples: {len(full_audio)}, duration: {len(full_audio)/SAMPLE_RATE:.2f}s")
                        print(f"   Audio range: [{full_audio.min()}, {full_audio.max()}]")
                        
                        # å¢åŠ éŸ³é‡ï¼ˆå¦‚æœå¤ªå°ï¼‰
                        max_val = np.abs(full_audio).max()
                        if max_val > 0:
                            if max_val < 10000:
                                volume_boost = 10000 / max_val
                                full_audio = (full_audio * volume_boost).astype(np.int16)
                                print(f"   ğŸ”Š Volume boosted by {volume_boost:.2f}x")
                            
                            # æ’­æ”¾éŸ³é¢‘
                            print(f"   â–¶ï¸  Playing audio now...")
                            sd.play(full_audio, samplerate=SAMPLE_RATE, blocking=True)
                            print("   âœ… Playback complete!")
                        else:
                            print("   âš ï¸  Audio data is silent")
                    
                    # æ˜¾ç¤ºè½¬å†™æ–‡æœ¬
                    transcript = content.get("transcript", "")
                    if transcript:
                        print(f"\nğŸ“ Transcript: {transcript}")
                        
        except Exception as e:
            print(f"\nâŒ Error processing output_item: {e}")
            import traceback
            traceback.print_exc()
    
    elif msg_type == "response.done":
        print("ğŸ‰ Response complete\n" + "="*40)
        
    elif msg_type == "input_audio_buffer.committed":
        print("âœ… Audio buffer committed")
        
    elif msg_type == "input_audio_buffer.speech_started":
        print("\nğŸ¤ Speech detected by server VAD")
        
    elif msg_type == "input_audio_buffer.speech_stopped":
        print("â¸ï¸  Speech ended (detected by server VAD)")
        
    elif msg_type in ("session.error", "error"):
        error_info = data.get('error', {})
        error_code = error_info.get('code', '')
        
        # åªæ˜¾ç¤ºéé€Ÿç‡é™åˆ¶çš„é”™è¯¯ï¼Œé€Ÿç‡é™åˆ¶é”™è¯¯å¤ªå¤šä¼šåˆ·å±
        if error_code != 'rate_limit_error':
            print(f"âŒ Error: {error_info.get('message', data)}")
        
    elif msg_type == "heartbeat":
        pass
        
    elif msg_type in ("rate_limits.updated", "conversation.created", "conversation.updated"):
        # é™é»˜å¤„ç†è¿™äº›å¸¸è§æ¶ˆæ¯
        pass
        
    else:
        # åªæ‰“å°çœŸæ­£æœªçŸ¥çš„æ¶ˆæ¯ç±»å‹
        if not msg_type.startswith(("response.", "input_audio_buffer.")):
            print(f"ğŸ’¡ Message: {msg_type}")


def on_open(ws):
    """Called when WebSocket connection is established."""
    print("ğŸ”Œ WebSocket connected, configuring session...")
    session_config = {
        "type": "session.update",
        "session": {
            "input_audio_format": "pcm16",
            "output_audio_format": "pcm16",
            "turn_detection": {"type": "server_vad"},
            "voice": "male-qingse",
            "modalities": ["audio", "text"],  # æ˜ç¡®æŒ‡å®šè¦éŸ³é¢‘å’Œæ–‡æœ¬
            "beta_fields": {
                "chat_mode": "audio",
                "tts_source": "e2e"
            }
        }
    }
    print(f"ğŸ“¤ Session config: {json.dumps(session_config, ensure_ascii=False, indent=2)}")
    ws.send(json.dumps(session_config))
    time.sleep(0.5)
    threading.Thread(target=send_audio_loop, args=(ws,), daemon=True).start()

def on_close(ws, close_status_code, close_msg):
    """Called when WebSocket connection closes."""
    if not stop_event.is_set():
         stop_event.set()
    print(f"\nğŸ”Œ Connection closed: code={close_status_code}, msg={close_msg}")

def on_error(ws, error):
    """Called on WebSocket error."""
    if not stop_event.is_set():
         stop_event.set()
    print(f"âŒ WebSocket error: {error}", file=sys.stderr)

# --- Main Program Logic ---

if __name__ == "__main__":
    if not API_KEY:
        print("âŒ Please set the ZHIPU_API_KEY environment variable first")
        sys.exit(1)

    # å…ˆæ£€æŸ¥éŸ³é¢‘è®¾å¤‡
    print("\n" + "="*50)
    print("ğŸ”Š Audio Device Check")
    print("="*50)
    try:
        devices = sd.query_devices()
        print(f"Default input device: {sd.query_devices(kind='input')['name']}")
        print(f"Default output device: {sd.query_devices(kind='output')['name']}")
        
        # æµ‹è¯•éŸ³é¢‘æ’­æ”¾
        print("\nğŸ§ª Testing audio playback...")
        test_tone = (np.sin(2 * np.pi * 440 * np.arange(SAMPLE_RATE) / SAMPLE_RATE) * 5000).astype(np.int16)
        sd.play(test_tone, samplerate=SAMPLE_RATE, blocking=True)
        print("âœ… If you heard a beep, audio output is working!")
        time.sleep(0.5)
    except Exception as e:
        print(f"âš ï¸  Audio device warning: {e}")
    print("="*50 + "\n")

    try:
        AUTH_TOKEN = generate_jwt_token(API_KEY)
        print("âœ… JWT generated successfully")
    except Exception as e:
        print(f"âŒ JWT generation failed: {e}")
        sys.exit(1)

    print("\n" + "="*50)
    print("    GLM-Realtime Voice Chat")
    print("="*50)
    print("ğŸ’¡ Usage:")
    print("   1. Speak into the microphone")
    print("   2. Pause for 1.5 seconds to get response")
    print("   3. Press Ctrl+C to exit")
    print("="*50 + "\n")
    
    websocket.enableTrace(False)
    
    ws = websocket.WebSocketApp(
        WS_URL,
        header=[f"Authorization: Bearer {AUTH_TOKEN}"],
        on_message=on_message,
        on_open=on_open,
        on_close=on_close,
        on_error=on_error
    )
    
    ws_thread = threading.Thread(target=ws.run_forever, daemon=True)
    ws_thread.start()

    try:
        print("â³ Waiting for connection...")
        session_ready.wait(timeout=10)

        if not session_ready.is_set():
            print("âŒ Session setup timeout")
            sys.exit(1)

        print("ğŸ¤ Ready! Start speaking...\n")
        
        with sd.InputStream(channels=1, samplerate=SAMPLE_RATE, dtype='int16', callback=callback):
            ws_thread.join()

    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Interrupted by user")
    except Exception as e:
        print(f"\nâŒ Runtime error: {e}")
    finally:
        stop_event.set()
        if ws:
             threading.Thread(target=ws.close).start()
        sd.stop()
        print("Exiting.")